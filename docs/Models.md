# Модели и их параметры

**Whisper** — это мультимодальная модель для обработки речи: она может преобразовывать речь в текст, переводить её на английский язык и определять язык исходного аудиофайла. В этом проекте используются 2 функции: преобразование аудио в текст и определение языка. 

Все варианты модели обучены на большом наборе разнообразных аудиальных данных, а отличаются количеством параметров. Чем больше параметров, тем "умнее" модель и больше ресурсов (оперативной памяти, в первую очередь) ей нужно для корректной работы. Для большинства задач достаточно `base`. 

Кроме параметров внутри модели, на результат влияют настройки модели при запуске задачи. В приложении представлены готовые [пресеты](../src/static/presets.yaml) с готовыми настройками. Они созданы в сотрудничестве с ChatGPT. Некоторые настройки, заложенные в пресетах:

- `temperature` — грубо говоря, степень "креативности" модели. Чем хуже качество звука, тем выше должна быть температура
- `best_of` — количество вариантов, из которых Whisper будет выбирать "лучший вариант" при условии `temperature > 0`
- `beam_size` — количество сценариев, которые Whisper рассматривает и разветвляет при алгоритме Beam Search
- `no_speech_threshold` — минимальное значение, ниже которого часть обрабатываемого материала игнорируется как не содержащая речь

Настройки вне пресетов: 

- `Язык` — на каком языке говорят в аудиофайле. Если известен, лучше указать — модель с меньшей вероятностью будет галлюцинировать 
- `Word timestmaps` — размечать ли вероятности и временные отметки для каждого слова в сегменте (будет в Excel-файле). Может быть полезно для глубокой обработки, но замедляет процесс обработки. Не рекомендуется включать без острой необходимости
- `FP16` — энергоёмкий режим: выше производительность, но ниже точность.

Источник: [Whisper](https://github.com/openai/whisper/tree/v20250625)